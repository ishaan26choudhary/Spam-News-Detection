{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc739be9-63d7-436b-9b44-b26101ad8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6db7688-577e-40c8-9f58-566cba768345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv files and storing the datasets in rn and fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d56cb70-51b4-4599-a767-a36c06b3d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn=pd.read_csv('Real.csv')\n",
    "fn=pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3697ad3b-f61f-474e-953c-2ceb81b11a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an additional attribute 'label' and putting  for real news and 1 for fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc77d332-02e9-4024-9ec7-8e6ea8da47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn['label']=0\n",
    "fn['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d38eeae-45e1-4396-bea1-fb4313e8beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take our training columns as 'Text' for our target column 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a84e076-d966-40d3-9986-28c558ce95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=rn[['Text','label']]\n",
    "dataset2=fn[['Text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be228acf-e4b7-4118-baf5-c8286f84966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating dataset1 and dataset2 in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f36c03-0a11-492b-94ef-2637af0e2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat((dataset1,dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae319896-f28b-40be-a30b-91dfc28c3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check whether data points have any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d10b718-b3c8-41fe-92cc-8ce9469a863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e98e06-dd4d-452c-9771-2bc8b79d9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking no of 1's or 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c47c680-4e51-43a0-b380-aa60e9f01f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    10\n",
       "1    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9bd27c1-2e3c-48c7-a28f-847639123152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed55a22-20a3-447c-af97-11c1f5b77e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86d71df-f7c4-4930-a2a7-ab3a203d2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For using NLP, we import following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c1620e-e0eb-4833-807b-baad53fbec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da46899-190f-42a2-b3af-fd7c9b245660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance for wordnetlemmatizer and stopwords for english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6472dfe2-c62b-441c-9279-f082dcdb4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=WordNetLemmatizer()\n",
    "stopwords=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5d0137-4148-45bc-b582-8910237e6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert our words in lower case and remove special case characters, we use clean_row function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d754c2ad-73d7-4b7f-a747-8c122627724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row(row):\n",
    "    row=row.lower()\n",
    "    row=re.sub('[^a-zA-Z]',' ',row)\n",
    "    token=row.split()\n",
    "    news=[ps.lemmatize(word) for word in token if word not in stopwords]\n",
    "    cleanned_news=' '.join(news)\n",
    "    return cleanned_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b43bfe89-9daf-425e-90c6-8796f0a5be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the text section, we type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cae85c6-c8d9-4d66-8681-97602f89296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Text']=dataset['Text'].apply(lambda x:clean_row(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902d9356-35d3-4e88-adf7-0932c200fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8           doomsday prophecy claim world end tomorrow\n",
      "6    government announced new education policy focu...\n",
      "3      government announced ban social medium platform\n",
      "7    two major tech company announced merger promis...\n",
      "2    researcher made breakthrough quantum computing...\n",
      "4    stock market reached record high today boostin...\n",
      "4    celebrity reportedly seen two different place ...\n",
      "6    new scheme claim give away free money anyone sign\n",
      "3    national election concluded peacefully high vo...\n",
      "5    historic space mission launched today aiming e...\n",
      "8    new gene therapy developed treat rare genetic ...\n",
      "5     scientist allegedly invented time travel machine\n",
      "0    report claim alien invaded major city causing ...\n",
      "2       miracle cure discovered cure disease instantly\n",
      "9    ancient fountain youth discovered promising et...\n",
      "1    new pill claim help people lose weight without...\n",
      "7       report indicate zombie outbreak remote village\n",
      "0    world leader reached historic agreement combat...\n",
      "1    scientist discovered new treatment significant...\n",
      "9    relief effort underway following natural disas...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3ff5e5-c3e4-4d84-82cf-3adc6786c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert the cleaned data into vectors, we import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e7fb3d5-9be7-498c-9265-3cc296709fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e594e9e-b705-476e-b0d9-778fb0437da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and create its instance in 'vectorizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "628c00e5-0a17-4235-9ac4-d2fd68727b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(max_features=56,lowercase=False,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76b72b92-5433-4226-a1c3-cfa050abd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To put first and second columns in variable x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ed8b2f7-2456-4661-a975-ce8d2cc8c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:20,0]\n",
    "y=dataset.iloc[:20,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31a6c1b9-4c77-4f68-a5ec-5a496946af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the dataset into training and testing sets, we import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ce09fe6-23e3-4ca8-91b0-426dbf89c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1af4c634-1fa5-44a3-9201-7f5bd9e870bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to have 20% of the rows in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da3b37e-8ac8-47f5-b49b-137cf98414b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data,train_label,test_label=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e364667-842e-4283-94d7-718f732df148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To vectorize the training data and convert the returned matrix to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08f3be23-9a7c-48c2-a542-d55d70afdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_train_data=vectorizer.fit_transform(train_data)\n",
    "vec_train_data=vec_train_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b06bd29-82a1-4f28-9287-5367a0621933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 56)\n"
     ]
    }
   ],
   "source": [
    "print(vec_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3727766b-dd1c-4b9b-a992-1fceeda7702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9791bca5-ac80-475b-bb41-7b1a8fca7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_test_data=vectorizer.fit_transform(test_data)\n",
    "vec_test_data=vec_test_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbef34f4-4b75-451d-b1a2-3a643112a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 56)\n"
     ]
    }
   ],
   "source": [
    "print(vec_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efa1a1f7-3270-43e6-85c9-3cc98ff77feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert these final training and test data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad0a01f3-f30a-4587-8cd9-770cae78519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.DataFrame(vec_train_data,columns=vectorizer.get_feature_names_out())\n",
    "test_data=pd.DataFrame(vec_test_data,columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f57d197b-77b0-401f-9fb0-587ebf9b337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fde270c5-c8f9-4492-8a56-8c9c985fd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the model using naive bayes, MultinomialNB library is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62a303a4-e02f-421f-9e90-1c842827a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0303a4d0-9848-4f97-a420-c8aab315000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and its instance is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cf21989-b0d9-489c-819a-2f089b8cd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37bb61fc-db3f-4c13-a862-29c19c3f822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fit the train data and train label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48c0bed7-05d3-454d-a368-0c9aabb604b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f6fb46a-4b56-4f93-95d8-c69e2e58a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict the values of train data and store its predicted values in a variable 'y_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55cd5dd7-8c24-4206-96b6-2396674e7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=clf.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34f8c149-068e-456d-ac0a-b116ef3e0efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b590990-f98f-46e3-ae4d-d8ab7cc430e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8    0\n",
      "0    0\n",
      "4    1\n",
      "2    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "9    1\n",
      "5    0\n",
      "6    1\n",
      "7    1\n",
      "5    1\n",
      "7    0\n",
      "8    1\n",
      "1    1\n",
      "0    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13df7ba4-075d-475f-9287-d79729c04d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To measure the accuracy of our model in predicting values, we import accuracy_score library as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98c7479f-bfdb-4138-8c4e-fb3472420938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51679ea9-2f87-409e-9257-c40d08c91b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print its accuracy on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f1be636-54a6-428b-8fe7-86279e8003f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(test_label,y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53d77b0e-f7d9-4d1b-8bbe-907ea12cc7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the news text:  Yeh exists !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaan\\OneDrive\\Attachments\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "txt =input(\"Enter the news text: \")\n",
    "new=clean_row(txt)\n",
    "pred=clf.predict(vectorizer.transform([new]).toarray())\n",
    "if pred==1:\n",
    "    print(\"Fake news !\")\n",
    "elif pred==0:\n",
    "    print(\"Real news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8041916-59cc-434c-ac73-0df757558e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c794ae1-ccd2-495c-97e7-55efee7c3fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ce48bcb-24c9-40ad-933f-741c7a1bbf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4744394d-77ad-4498-a108-56bc203bc3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0\n",
      "8    0\n",
      "1    1\n",
      "9    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8b712-9021-48c9-8f03-8311d9893ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
